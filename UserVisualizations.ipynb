{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50b709d5",
   "metadata": {},
   "source": [
    "## Visualizations of User Data\n",
    "This notebook contains the code for the visualization featured in the presentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2e1ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing and Cleaning Data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from random import randint\n",
    "from modules.lavenshtein import lavenshtein\n",
    "import seaborn as sns\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "# Cleaning User Data\n",
    "users_data = pd.read_csv(\"data/original/Users.csv\")\n",
    "\n",
    "# Dates\n",
    "date_series = []\n",
    "temp_date_df = users_data[\"date\"].copy()\n",
    "temp_date_df = temp_date_df.str.split(\"-\")\n",
    "for date in temp_date_df:\n",
    "    length_lst = np.array(list(map(lambda x: len(x), date))) # Get str lengths\n",
    "    year = date[np.argmax(length_lst)]\n",
    "    # Construct new year\n",
    "    if int(year[-1]) in [6, 7, 8]:\n",
    "        year = \"201\" + str(year[-1])\n",
    "    else:\n",
    "        year = \"201\" + str(randint(6,8))\n",
    "    if int(date[1]) > 12: # Check where day and month are\n",
    "        if int(date[2]) > 12:\n",
    "            day = date[1]\n",
    "            month = str(randint(1,12)) # There's few enough cases that this should be alright\n",
    "        else:\n",
    "            day = date[1]\n",
    "            month = date[2]\n",
    "    else:\n",
    "        day = date[2]\n",
    "        month = date[1]\n",
    "    # Construct new day\n",
    "    if int(day) > 31:\n",
    "        day = str(randint(1,2)) + str(day[-1])\n",
    "    # Construct new date and add to users_data\n",
    "    new_date = year + \"-\" + month + \"-\" + day\n",
    "    date_series.append(new_date)\n",
    "users_data[\"date\"] = pd.to_datetime(date_series)\n",
    "\n",
    "def laven_calc(cand_name, cand_lst, p_insert=1, p_delete=1, p_edit=1):\n",
    "    laven_score = lavenshtein(cand_lst.iloc[0], cand_name, p_insert=p_insert, p_delete=p_delete, p_edit=p_edit)\n",
    "    laven_score /= len(cand_name) # Normalize score based on string length\n",
    "    return cand_lst[cand_lst == cand_name].index[0], laven_score\n",
    "\n",
    "temp_vname_df = users_data[\"vendor_name\"].copy() # Return List\n",
    "candidate_list = users_data[\"vendor_name\"].copy() # Iteration List\n",
    "while len(candidate_list) > 0:\n",
    "    temp_cand_array = candidate_list.copy()\n",
    "    lavens = temp_cand_array.apply(laven_calc, cand_lst=temp_cand_array, p_insert=0.5, p_delete=0.5, p_edit=1)\n",
    "    matches = list(filter(lambda x: x[1] < 0.4, lavens)) # Consider scores where less than 40% of word is edited\n",
    "    matches = list(dict.fromkeys(matches)) # Remove weird duplicates\n",
    "    replace_name = candidate_list.iloc[0] # Get name to replace matches with\n",
    "    remove_idx = list(map(lambda x: x[0], matches))\n",
    "    temp_vname_df.iloc[remove_idx,] = replace_name # Replace entries\n",
    "    candidate_list = candidate_list.drop(remove_idx) # Remove matches from candidates\n",
    "    candidate_list = candidate_list[~candidate_list.isin([replace_name])] # Remove matches from candidates\n",
    "    print(len(candidate_list))\n",
    "users_data[\"vendor_name\"] = temp_vname_df\n",
    "\n",
    "# Cleaning Vendor Addresses\n",
    "temp_vadd_df = users_data[\"vendor_address\"].copy() # Return List\n",
    "candidate_list = users_data[\"vendor_address\"].copy() # Iteration List\n",
    "while len(candidate_list) > 0:\n",
    "    temp_cand_array = candidate_list.copy()\n",
    "    lavens = temp_cand_array.apply(laven_calc, cand_lst=temp_cand_array, p_insert=0.5, p_delete=0.5, p_edit=1)\n",
    "    matches = list(filter(lambda x: x[1] < 0.1, lavens)) # Consider scores where less than 10% of str is different\n",
    "    matches = list(dict.fromkeys(matches)) # Remove weird duplicates\n",
    "    replace_name = candidate_list.iloc[0] # Get name to replace matches with\n",
    "    remove_idx = list(map(lambda x: x[0], matches))\n",
    "    temp_vname_df.iloc[remove_idx,] = replace_name # Replace entries\n",
    "    candidate_list = candidate_list.drop(remove_idx) # Remove matches from candidates\n",
    "    candidate_list = candidate_list[~candidate_list.isin([replace_name])] # Remove matches from candidates\n",
    "    print(len(candidate_list))\n",
    "users_data[\"vendor_address\"] = temp_vadd_df\n",
    "\n",
    "# Cleaning Amounts\n",
    "temp_amount_df = users_data[\"amount\"].copy() # Return List\n",
    "# Impute mean of company's amounts into missing value\n",
    "temp_amount_df.loc[temp_amount_df.isna()] = temp_amount_df.loc[users_data[\"vendor_name\"] == users_data.loc[419,\"vendor_name\"]].mean()\n",
    "users_data[\"amount\"] = temp_amount_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373d9042",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_vname_df = users_data[\"vendor_name\"].copy() # Return List\n",
    "candidate_list = users_data[\"vendor_name\"].copy() # Iteration List\n",
    "while len(candidate_list) > 0:\n",
    "    temp_cand_array = candidate_list.copy()\n",
    "    lavens = temp_cand_array.apply(laven_calc, cand_lst=temp_cand_array, p_insert=0.5, p_delete=0.5, p_edit=1)\n",
    "    matches = list(filter(lambda x: x[1] < 0.4, lavens)) # Consider scores where less than 40% of word is edited\n",
    "    matches = list(dict.fromkeys(matches)) # Remove weird duplicates\n",
    "    replace_name = candidate_list.iloc[0] # Get name to replace matches with\n",
    "    remove_idx = list(map(lambda x: x[0], matches))\n",
    "    temp_vname_df.iloc[remove_idx,] = replace_name # Replace entries\n",
    "    candidate_list = candidate_list.drop(remove_idx) # Remove matches from candidates\n",
    "    candidate_list = candidate_list[~candidate_list.isin([replace_name])] # Remove matches from candidates\n",
    "    print(len(candidate_list))\n",
    "users_data[\"vendor_name\"] = temp_vname_df\n",
    "\n",
    "# Cleaning Vendor Addresses\n",
    "temp_vadd_df = users_data[\"vendor_address\"].copy() # Return List\n",
    "candidate_list = users_data[\"vendor_address\"].copy() # Iteration List\n",
    "while len(candidate_list) > 0:\n",
    "    temp_cand_array = candidate_list.copy()\n",
    "    lavens = temp_cand_array.apply(laven_calc, cand_lst=temp_cand_array, p_insert=0.5, p_delete=0.5, p_edit=1)\n",
    "    matches = list(filter(lambda x: x[1] < 0.1, lavens)) # Consider scores where less than 10% of str is different\n",
    "    matches = list(dict.fromkeys(matches)) # Remove weird duplicates\n",
    "    replace_name = candidate_list.iloc[0] # Get name to replace matches with\n",
    "    remove_idx = list(map(lambda x: x[0], matches))\n",
    "    temp_vname_df.iloc[remove_idx,] = replace_name # Replace entries\n",
    "    candidate_list = candidate_list.drop(remove_idx) # Remove matches from candidates\n",
    "    candidate_list = candidate_list[~candidate_list.isin([replace_name])] # Remove matches from candidates\n",
    "    print(len(candidate_list))\n",
    "users_data[\"vendor_address\"] = temp_vadd_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f016840f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Visualizing Data\n",
    "plt.figure(figsize=(10, 5))\n",
    "hist_chart = sns.histplot(users_data[\"amount\"].loc[users_data[\"amount\"]<200], kde=True, line_kws={\"lw\":5}, color=\"#017180\")\n",
    "plt.xlabel(\"Transaction Amount ($)\")\n",
    "plt.ylabel(\"# of Transactions\")\n",
    "plt.title(\"Distribution of Transaction Amounts\")\n",
    "plt.savefig('amount_histogram.png', bbox_inches='tight', dpi=300)\n",
    "plt.show(hist_chart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b9cb50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get figure values for animated graph\n",
    "hist_height = []\n",
    "hist_x = []\n",
    "for p in hist_chart.patches:\n",
    "    hist_height.append(p.get_height())\n",
    "    hist_x.append(p.get_x())\n",
    "print(hist_height, hist_x)\n",
    "hist_height = pd.Series(hist_height)\n",
    "hist_height.to_csv(\"hist_height.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a49fd80",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.violinplot(data=users_data.loc[users_data[\"vendor_name\"] == \"FOUR QUARTERS SDN BHD\"], x=\"vendor_name\", y=\"amount\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a781d88",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "unique_count = users_data[\"vendor_name\"].value_counts().reset_index()\n",
    "per_chart = sns.barplot(data=unique_count.loc[unique_count[\"vendor_name\"] > 1], x=\"index\", y=\"vendor_name\", palette=\"Spectral\")\n",
    "plt.xticks([])\n",
    "plt.title(\"Number of Transaction per Vendor\")\n",
    "plt.xlabel(\"Vendor\")\n",
    "plt.ylabel(\"# of Transactions\")\n",
    "#plt.savefig('amount_by_vendor.png', bbox_inches='tight', dpi=300)\n",
    "plt.show(per_chart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89634dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get figure values for animated graph\n",
    "per_height = []\n",
    "per_x = []\n",
    "for p in per_chart.patches:\n",
    "    per_height.append(p.get_height())\n",
    "    per_x.append(p.get_x())\n",
    "print(per_height, per_x)\n",
    "per_height = pd.Series(per_height)\n",
    "per_height.to_csv(\"per_height.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f62773c",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_count = users_data[\"vendor_name\"].value_counts().reset_index()\n",
    "unique_count.loc[unique_count[\"vendor_name\"] > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf9cfa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checks number of locations per vendor\n",
    "leng_lst = []\n",
    "for vendor in users_data[\"vendor_name\"]:\n",
    "    print(vendor)\n",
    "    new_leng = len(users_data[\"vendor_address\"].loc[users_data[\"vendor_name\"] == vendor].value_counts())\n",
    "    print(new_leng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e6065a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checks number of vendors per location\n",
    "leng_lst = []\n",
    "for address in users_data[\"vendor_address\"]:\n",
    "    print(address)\n",
    "    new_leng = users_data[\"vendor_name\"].loc[users_data[\"vendor_address\"] == address].value_counts()\n",
    "    print(new_leng)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
